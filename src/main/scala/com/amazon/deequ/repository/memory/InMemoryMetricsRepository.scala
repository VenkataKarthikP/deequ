/**
 * Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License"). You may not
 * use this file except in compliance with the License. A copy of the License
 * is located at
 *
 *     http://aws.amazon.com/apache2.0/
 *
 * or in the "license" file accompanying this file. This file is distributed on
 * an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
 * express or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 *
 */

package com.amazon.deequ.repository.memory

import com.amazon.deequ.analyzers.Analyzer
import com.amazon.deequ.metrics.Metric
import com.amazon.deequ.repository._
import com.amazon.deequ.analyzers.runners.AnalyzerContext

import scala.collection.JavaConversions._
import java.util.concurrent.ConcurrentHashMap

/** A simple Repository implementation backed by a concurrent hash map */
class InMemoryMetricsRepository() extends MetricsRepository {

  private val resultsRepository = new ConcurrentHashMap[ResultKey, AnalysisResult]()

  /**
    * Saves Analysis results (metrics)
    *
    * @param resultKey represents the version of the dataset deequ checks were run on.
    * @param analyzerContext The resulting AnalyzerContext of an Analysis
    */
  def save(resultKey: ResultKey, analyzerContext: AnalyzerContext): Unit = {

    val successfulMetrics = analyzerContext.metricMap.filter {
      case (_, metric) => metric.value.isSuccess
    }

    val analyzerContextWithSuccessfulValues = AnalyzerContext(successfulMetrics)

    resultsRepository.put(resultKey,
      AnalysisResult(resultKey, analyzerContextWithSuccessfulValues))
  }

  /**
    * Get an AnalyzerContext saved using exactly the same resultKey if present
    *
    * @param resultKey represents the version of the dataset deequ checks were run on.
    */
  def loadByKey(resultKey: ResultKey): Option[AnalyzerContext] = {
    Option(resultsRepository.get(resultKey)).map { _.analyzerContext }
  }

  /** Get a builder class to construct a loading query to get AnalysisResults */
  def load(): MetricsRepositoryMultipleResultsLoader = {
    LimitedInMemoryMetricsRepositoryMultipleResultsLoader(resultsRepository)
  }
}

/**
 * A loader for retrieving multiple metric results stored in-memory with limited scope.
 * This class provides functionality to load metrics from an in-memory repository,
 * optionally filtered by tag values, a set of analyzers, and a specified time range.
 * It is particularly useful for scenarios where metrics are stored temporarily or
 * when working with a smaller dataset that fits entirely in memory.
 *
 * @param resultsRepository The ConcurrentHashMap instance that holds the AnalysisResult objects.
 *                          This serves as the in-memory repository for storing and retrieving
 *                          metrics results.
 * @param tagValues Optional map of tag names to values used for filtering metrics. If specified,
 *                  only metrics that match these tag values will be loaded. If None, no tag-based
 *                  filtering is applied.
 * @param analyzers Optional sequence of analyzers. If specified, only metrics generated by
 *                  these analyzers will be considered. If None, metrics from all analyzers are
 *                  considered.
 * @param after Optional epoch timestamp representing the lower bound of the time range. If
 *              specified, only metrics generated after this timestamp are considered. If None,
 *              no lower time bound is applied.
 * @param before Optional epoch timestamp representing the upper bound of the time range. If
 *               specified, only metrics generated before this timestamp are considered. If None,
 *               no upper time bound is applied.
 *
 * Usage:
 * Instantiate this class with the required parameters, including the in-memory results repository.
 * The loader can then be used to retrieve filtered metric results based on the specified criteria.
 *
 * Example:
 * val inMemoryRepo = new ConcurrentHashMap[ResultKey, AnalysisResult]()
 * val loader = LimitedInMemoryMetricsRepositoryMultipleResultsLoader(
 *     inMemoryRepo,
 *     Some(Map("tagKey" -> "tagValue")),
 *     Some(Seq(analyzer1, analyzer2)),
 *     Some(1609459200000L), // Jan 1, 2021
 *     Some(1612137600000L)) // Feb 1, 2021
 * val results = loader.load()
 */
case class LimitedInMemoryMetricsRepositoryMultipleResultsLoader(
    resultsRepository: ConcurrentHashMap[ResultKey, AnalysisResult],
    private val tagValues: Option[Map[String, String]] = None,
    private val analyzers: Option[Seq[Analyzer[_, Metric[_]]]] = None,
    private val after: Option[Long] = None,
    private val before: Option[Long] = None) extends MetricsRepositoryMultipleResultsLoader {


  /**
    * Filter out results that don't have specific values for specific tags
    *
    * @param tagValues Map with tag names and the corresponding values to filter for
    */
  def withTagValues(tagValues: Map[String, String]): MetricsRepositoryMultipleResultsLoader =
    this.copy(tagValues = Some(tagValues))

  /**
    * Choose all metrics that you want to load
    *
    * @param analyzers A sequence of analyers who's resulting metrics you want to load
    */
  def forAnalyzers(analyzers: Seq[Analyzer[_, Metric[_]]])
    : MetricsRepositoryMultipleResultsLoader = this.copy(analyzers = Some(analyzers))

  /**
    * Only look at AnalysisResults with a history key with a smaller value
    *
    * @param dateTime The maximum dateTime of AnalysisResults to look at
    */
  def before(dateTime: Long): MetricsRepositoryMultipleResultsLoader = this.copy(before = Some(dateTime))

  /**
    * Only look at AnalysisResults with a history key with a greater value
    *
    * @param dateTime The minimum dateTime of AnalysisResults to look at
    */
  def after(dateTime: Long): MetricsRepositoryMultipleResultsLoader = this.copy(after = Some(dateTime))

  /** Get the AnalysisResult */
  def get(): Seq[AnalysisResult] = {
    resultsRepository
      .filterKeys(key => after.isEmpty || after.get <= key.dataSetDate)
      .filterKeys(key => before.isEmpty || key.dataSetDate <= before.get)
      .filterKeys(key => tagValues.isEmpty || tagValues.get.toSet.subsetOf(key.tags.toSet))
      .values
      .map { analysisResult =>

        val requestedMetrics = analysisResult
          .analyzerContext
          .metricMap
          .filterKeys(analyzer => analyzers.isEmpty || analyzers.get.contains(analyzer))

        AnalysisResult(analysisResult.resultKey, AnalyzerContext(requestedMetrics))
      }
      .toSeq
  }
}
